import pandas as pd
import numpy as np
from sklearn.datasets import fetch_openml
import warnings
warnings.filterwarnings('ignore')

# íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë¡œë“œ
print("ğŸš¢ íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë¡œë”© ì¤‘...")
titanic = fetch_openml(name='titanic', version=1, as_frame=True)
df = titanic.frame

print(f"ğŸ“Š ë°ì´í„° í˜•íƒœ: {df.shape}")
print(f"ğŸ“‹ ì»¬ëŸ¼: {df.columns.tolist()}")

print("\n" + "="*60)
print("ğŸ”§ KLIB ìƒì„¸ ë¶„ì„")
print("="*60)

# ============================================================================
# 1. ë°ì´í„° ì •ë³´ ìš”ì•½
# ============================================================================
print("\nğŸ“‹ 1. ë°ì´í„° ì •ë³´ ìš”ì•½:")
print("="*40)
print(df.info())

# ============================================================================
# 2. ê²°ì¸¡ì¹˜ ë¶„ì„
# ============================================================================
print("\nğŸ” 2. ê²°ì¸¡ì¹˜ ë¶„ì„:")
print("="*40)
missing_data = df.isnull().sum()
missing_percent = (missing_data / len(df)) * 100

missing_df = pd.DataFrame({
    'ê²°ì¸¡ì¹˜ ê°œìˆ˜': missing_data,
    'ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)': missing_percent
})

print("ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼:")
print(missing_df[missing_df['ê²°ì¸¡ì¹˜ ê°œìˆ˜'] > 0].sort_values('ê²°ì¸¡ì¹˜ ê°œìˆ˜', ascending=False))

# ============================================================================
# 3. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„ì„
# ============================================================================
print("\nğŸ“Š 3. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„ì„:")
print("="*40)
numeric_cols = df.select_dtypes(include=[np.number]).columns
print(f"ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {list(numeric_cols)}")

# ê¸°ìˆ í†µê³„
print("\nğŸ“ˆ ê¸°ìˆ í†µê³„:")
print(df[numeric_cols].describe())

# ============================================================================
# 4. ìƒê´€ê´€ê³„ ë¶„ì„
# ============================================================================
print("\nğŸ“Š 4. ìƒê´€ê´€ê³„ ë¶„ì„:")
print("="*40)
if len(numeric_cols) > 1:
    correlation_matrix = df[numeric_cols].corr()
    print("ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„:")
    print(correlation_matrix.round(3))
    
    # ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸°
    print("\nğŸ” ë†’ì€ ìƒê´€ê´€ê³„ (ì ˆëŒ“ê°’ > 0.5):")
    high_corr = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_val = correlation_matrix.iloc[i, j]
            if abs(corr_val) > 0.5:
                high_corr.append((correlation_matrix.columns[i], correlation_matrix.columns[j], corr_val))
    
    for var1, var2, corr_val in high_corr:
        print(f"  {var1} â†” {var2}: {corr_val:.3f}")

# ============================================================================
# 5. ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„
# ============================================================================
print("\nğŸ“Š 5. ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„:")
print("="*40)
categorical_cols = df.select_dtypes(include=['category', 'object']).columns
print(f"ë²”ì£¼í˜• ë³€ìˆ˜: {list(categorical_cols)}")

for col in categorical_cols:
    if col != 'name':  # ì´ë¦„ì€ ë„ˆë¬´ ë§ìœ¼ë¯€ë¡œ ì œì™¸
        print(f"\nğŸ“‹ {col}:")
        value_counts = df[col].value_counts()
        print(f"  ê³ ìœ ê°’ ê°œìˆ˜: {len(value_counts)}")
        print(f"  ìƒìœ„ 5ê°œ ê°’:")
        for val, count in value_counts.head().items():
            print(f"    {val}: {count}ê°œ ({count/len(df)*100:.1f}%)")

# ============================================================================
# 6. ìƒì¡´ë¥  ë¶„ì„
# ============================================================================
print("\nğŸ“Š 6. ìƒì¡´ë¥  ë¶„ì„:")
print("="*40)

# survived ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜
survived_numeric = pd.to_numeric(df['survived'], errors='coerce')

print(f"ì „ì²´ ìƒì¡´ë¥ : {survived_numeric.mean():.2%}")

# ì„±ë³„ ìƒì¡´ë¥ 
if 'sex' in df.columns:
    survival_by_sex = df.groupby('sex')['survived'].apply(lambda x: pd.to_numeric(x, errors='coerce').mean())
    print(f"\nğŸ‘¥ ì„±ë³„ ìƒì¡´ë¥ :")
    for sex, rate in survival_by_sex.items():
        print(f"  {sex}: {rate:.2%}")

# í´ë˜ìŠ¤ë³„ ìƒì¡´ë¥ 
if 'pclass' in df.columns:
    survival_by_class = df.groupby('pclass')['survived'].apply(lambda x: pd.to_numeric(x, errors='coerce').mean())
    print(f"\nğŸ« í´ë˜ìŠ¤ë³„ ìƒì¡´ë¥ :")
    for pclass, rate in survival_by_class.items():
        print(f"  {pclass}ë“±ê¸‰: {rate:.2%}")

# ë‚˜ì´ë³„ ìƒì¡´ë¥ 
if 'age' in df.columns:
    df['age_group'] = pd.cut(pd.to_numeric(df['age'], errors='coerce'), 
                             bins=[0, 18, 30, 50, 100], 
                             labels=['Child', 'Young', 'Adult', 'Senior'])
    age_survival = df.groupby('age_group')['survived'].apply(lambda x: pd.to_numeric(x, errors='coerce').mean())
    print(f"\nğŸ‘¶ ë‚˜ì´ëŒ€ë³„ ìƒì¡´ë¥ :")
    for age_group, rate in age_survival.items():
        print(f"  {age_group}: {rate:.2%}")

print("\nâœ… Klib ìƒì„¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!") 