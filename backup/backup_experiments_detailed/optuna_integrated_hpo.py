import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
import optuna
from autogluon.tabular import TabularPredictor
from autogluon.tabular.registry import ag_model_registry
from custom_models.tabular_deepfm_torch_model import TabularDeepFMTorchModel
from custom_models.tabular_dcnv2_torch_model import TabularDCNv2TorchModel
from custom_models.tabular_dcnv2_fuxictr_torch_model_fixed import TabularDCNv2FuxiCTRTorchModel
from custom_models.focal_loss_implementation import CustomFocalDLModel
from custom_models.custom_nn_torch_model import CustomNNTorchModel
from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_openml
import time

# ëª¨ë¸ ë“±ë¡
ag_model_registry.add(TabularDeepFMTorchModel)
ag_model_registry.add(TabularDCNv2TorchModel)
ag_model_registry.add(TabularDCNv2FuxiCTRTorchModel)
ag_model_registry.add(CustomFocalDLModel)
ag_model_registry.add(CustomNNTorchModel)

def load_data():
    """Titanic ë°ì´í„° ë¡œë“œ"""
    print("Titanic ë°ì´í„° ë¡œë“œ ì¤‘...")
    titanic = fetch_openml("titanic", version=1, as_frame=True)
    df = titanic.frame
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    df = df.dropna(subset=['survived'])
    df['survived'] = df['survived'].astype(int)
    
    # ë°ì´í„° ë¶„í• 
    train_data, test_data = train_test_split(
        df,
        test_size=0.2,
        random_state=42,
        stratify=df['survived']
    )
    
    print(f"í›ˆë ¨ ë°ì´í„°: {len(train_data)}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê°œ")
    
    return train_data, test_data

def create_integrated_objective(train_data, test_data):
    """í†µí•© Optuna objective í•¨ìˆ˜"""
    
    def objective(trial):
        # ëª¨ë“  ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í•œë²ˆì— íƒìƒ‰
        hyperparameters = {}
        
        # DCNV2 í•˜ì´í¼íŒŒë¼ë¯¸í„°
        if trial.suggest_categorical('use_dcnv2', [True, False]):
            hyperparameters['DCNV2'] = {
                'learning_rate': trial.suggest_float('dcnv2_lr', 1e-4, 1e-2, log=True),
                'weight_decay': trial.suggest_float('dcnv2_wd', 1e-6, 1e-3, log=True),
                'dropout_prob': trial.suggest_categorical('dcnv2_dropout', [0.1, 0.2, 0.3]),
                'num_layers': trial.suggest_categorical('dcnv2_layers', [3, 4, 5]),
                'hidden_size': trial.suggest_categorical('dcnv2_hidden', [128, 256, 512]),
                'num_epochs': trial.suggest_categorical('dcnv2_epochs', [15, 20, 25]),
            }
        
        # Focal Loss í•˜ì´í¼íŒŒë¼ë¯¸í„°
        if trial.suggest_categorical('use_focal', [True, False]):
            hyperparameters['CUSTOM_FOCAL_DL'] = {
                'learning_rate': trial.suggest_float('focal_lr', 1e-4, 1e-2, log=True),
                'weight_decay': trial.suggest_float('focal_wd', 1e-6, 1e-3, log=True),
                'dropout_prob': trial.suggest_categorical('focal_dropout', [0.1, 0.2, 0.3]),
                'num_layers': trial.suggest_categorical('focal_layers', [3, 4, 5]),
                'hidden_size': trial.suggest_categorical('focal_hidden', [128, 256, 512]),
                'num_epochs': trial.suggest_categorical('focal_epochs', [15, 20, 25]),
                'focal_alpha': trial.suggest_categorical('focal_alpha', [0.25, 0.5, 0.75, 1.0]),
                'focal_gamma': trial.suggest_categorical('focal_gamma', [1.0, 2.0, 3.0]),
            }
        
        # RF í•˜ì´í¼íŒŒë¼ë¯¸í„°
        if trial.suggest_categorical('use_rf', [True, False]):
            hyperparameters['RF'] = {
                'n_estimators': trial.suggest_categorical('rf_n_estimators', [50, 100, 200]),
                'max_depth': trial.suggest_categorical('rf_max_depth', [5, 10, 15, None]),
                'min_samples_split': trial.suggest_categorical('rf_min_split', [2, 5, 10]),
                'min_samples_leaf': trial.suggest_categorical('rf_min_leaf', [1, 2, 4]),
            }
        
        # ìµœì†Œ 1ê°œ ëª¨ë¸ì€ ì‚¬ìš©
        if not hyperparameters:
            hyperparameters['RF'] = {
                'n_estimators': 100,
                'max_depth': 10,
                'min_samples_split': 5,
                'min_samples_leaf': 2,
            }
        
        # AutoGluon Predictor ì„¤ì •
        predictor = TabularPredictor(
            label='survived',
            problem_type='binary',
            eval_metric='f1',
            path=f"models/optuna_integrated_{trial.number}",
            verbosity=2
        )
        
        # ëª¨ë¸ í•™ìŠµ
        try:
            predictor.fit(
                train_data=train_data,
                hyperparameters=hyperparameters,
                time_limit=600,  # 10ë¶„ ì œí•œ
                presets='medium_quality'
            )
            
            # ê²€ì¦ ì„±ëŠ¥ í‰ê°€
            val_scores = predictor.leaderboard()
            if len(val_scores) > 0:
                best_score = val_scores.iloc[0]['score_val']
                print(f"Trial {trial.number}: ì•™ìƒë¸” - F1 = {best_score:.4f}")
                print(f"ì‚¬ìš©ëœ ëª¨ë¸: {list(hyperparameters.keys())}")
                return best_score
            else:
                return 0.0
                
        except Exception as e:
            print(f"Trial {trial.number} ì‹¤íŒ¨: {e}")
            return 0.0
    
    return objective

def run_integrated_hpo():
    """í†µí•© Optuna HPO ì‹¤í—˜"""
    print("=== í†µí•© Optuna HPO ì‹¤í—˜ ì‹œì‘ ===")
    
    # ë°ì´í„° ë¡œë“œ
    train_data, test_data = load_data()
    
    # í†µí•© Optuna study ìƒì„±
    study = optuna.create_study(
        direction='maximize',
        study_name='integrated_optuna_study'
    )
    
    # Objective í•¨ìˆ˜ ìƒì„±
    objective = create_integrated_objective(train_data, test_data)
    
    # Optuna ìµœì í™” ì‹¤í–‰
    study.optimize(
        objective,
        n_trials=20,  # 20ë²ˆ ì‹œë„
        timeout=3600,  # 1ì‹œê°„ ì œí•œ
        show_progress_bar=True
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š í†µí•© ìµœì í™” ê²°ê³¼:")
    print(f"ìµœê³  ì„±ëŠ¥: {study.best_value:.4f}")
    print(f"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {study.best_params}")
    
    # ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
    print("\nğŸš€ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ...")
    best_hyperparameters = {}
    
    # ìµœì  íŒŒë¼ë¯¸í„°ì—ì„œ ëª¨ë¸ë³„ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    best_params = study.best_params
    
    if best_params.get('use_dcnv2', False):
        best_hyperparameters['DCNV2'] = {
            'learning_rate': best_params['dcnv2_lr'],
            'weight_decay': best_params['dcnv2_wd'],
            'dropout_prob': best_params['dcnv2_dropout'],
            'num_layers': best_params['dcnv2_layers'],
            'hidden_size': best_params['dcnv2_hidden'],
            'num_epochs': best_params['dcnv2_epochs'],
        }
    
    if best_params.get('use_focal', False):
        best_hyperparameters['CUSTOM_FOCAL_DL'] = {
            'learning_rate': best_params['focal_lr'],
            'weight_decay': best_params['focal_wd'],
            'dropout_prob': best_params['focal_dropout'],
            'num_layers': best_params['focal_layers'],
            'hidden_size': best_params['focal_hidden'],
            'num_epochs': best_params['focal_epochs'],
            'focal_alpha': best_params['focal_alpha'],
            'focal_gamma': best_params['focal_gamma'],
        }
    
    if best_params.get('use_rf', False):
        best_hyperparameters['RF'] = {
            'n_estimators': best_params['rf_n_estimators'],
            'max_depth': best_params['rf_max_depth'],
            'min_samples_split': best_params['rf_min_split'],
            'min_samples_leaf': best_params['rf_min_leaf'],
        }
    
    # ìµœì¢… ëª¨ë¸ í•™ìŠµ
    final_predictor = TabularPredictor(
        label='survived',
        problem_type='binary',
        eval_metric='f1',
        path="models/optuna_final_ensemble",
        verbosity=2
    )
    
    final_predictor.fit(
        train_data=train_data,
        hyperparameters=best_hyperparameters,
        time_limit=1200,  # 20ë¶„ ì œí•œ
        presets='medium_quality'
    )
    
    # ìµœì¢… ì„±ëŠ¥ í‰ê°€
    final_scores = final_predictor.leaderboard()
    print(f"\nğŸ† ìµœì¢… ì•™ìƒë¸” ì„±ëŠ¥:")
    print(final_scores)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€
    test_predictions = final_predictor.predict(test_data)
    test_probabilities = final_predictor.predict_proba(test_data)
    
    from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score
    
    test_f1 = f1_score(test_data['survived'], test_predictions)
    test_acc = accuracy_score(test_data['survived'], test_predictions)
    test_prec = precision_score(test_data['survived'], test_predictions)
    test_rec = recall_score(test_data['survived'], test_predictions)
    
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥:")
    print(f"F1 Score: {test_f1:.4f}")
    print(f"Accuracy: {test_acc:.4f}")
    print(f"Precision: {test_prec:.4f}")
    print(f"Recall: {test_rec:.4f}")
    
    print("\nâœ… í†µí•© Optuna HPO ì‹¤í—˜ ì™„ë£Œ!")

if __name__ == "__main__":
    run_integrated_hpo() 