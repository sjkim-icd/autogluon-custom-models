import torch
import torch.nn.functional as F
import numpy as np

def check_focal_loss_implementation():
    """Focal Loss êµ¬í˜„ì„ ì›ë˜ ìˆ˜ì‹ê³¼ ë¹„êµ ë¶„ì„"""
    print("=== Focal Loss êµ¬í˜„ ê²€ì¦ ===\n")
    
    # 1. ì›ë˜ Focal Loss ìˆ˜ì‹ í™•ì¸
    print("ğŸ“š ì›ë˜ Focal Loss ìˆ˜ì‹:")
    print("FL(p_t) = -Î± * (1 - p_t)^Î³ * log(p_t)")
    print("ì—¬ê¸°ì„œ:")
    print("  - p_t: ì •ë‹µ í´ë˜ìŠ¤ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ ")
    print("  - Î±: í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • ê³„ìˆ˜")
    print("  - Î³: ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë‘ëŠ” ì§‘ì¤‘ë„ ì¡°ì ˆ ê³„ìˆ˜")
    print("  - log(p_t): CrossEntropyì˜ ê¸°ë³¸ ì†ì‹¤")
    print("  - (1 - p_t)^Î³: ì‰¬ìš´ ìƒ˜í”Œì˜ ì†ì‹¤ì„ ì¤„ì´ëŠ” ê°€ì¤‘ì¹˜\n")
    
    # 2. í˜„ì¬ êµ¬í˜„ ë¶„ì„
    print("ğŸ” í˜„ì¬ êµ¬í˜„ ë¶„ì„:")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size = 4
    num_classes = 2
    
    # ì˜ˆì¸¡ ë¡œì§“ (raw logits)
    logits = torch.tensor([
        [2.0, 1.0],  # Class 0ì— ë†’ì€ í™•ì‹ 
        [1.0, 2.0],  # Class 1ì— ë†’ì€ í™•ì‹   
        [0.5, 0.5],  # ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡
        [0.1, 3.0]   # Class 1ì— ë§¤ìš° ë†’ì€ í™•ì‹ 
    ], dtype=torch.float32)
    
    # ì •ë‹µ ë¼ë²¨
    targets = torch.tensor([0, 1, 0, 1], dtype=torch.long)
    
    print(f"ì…ë ¥ ë¡œì§“:\n{logits}")
    print(f"ì •ë‹µ ë¼ë²¨: {targets}\n")
    
    # 3. ë‹¨ê³„ë³„ ê³„ì‚° ê³¼ì •
    print("ğŸ“Š ë‹¨ê³„ë³„ ê³„ì‚° ê³¼ì •:")
    
    # Step 1: log_softmax ê³„ì‚°
    log_probs = F.log_softmax(logits, dim=1)
    print(f"1. log_softmax ê²°ê³¼:\n{log_probs}")
    
    # Step 2: í™•ë¥ ë¡œ ë³µì›
    probs = torch.exp(log_probs)
    print(f"2. í™•ë¥ ë¡œ ë³µì›:\n{probs}")
    
    # Step 3: ì •ë‹µ í´ë˜ìŠ¤ í™•ë¥  ì¶”ì¶œ
    pt = probs.gather(1, targets.unsqueeze(1)).squeeze(1)
    log_pt = log_probs.gather(1, targets.unsqueeze(1)).squeeze(1)
    print(f"3. ì •ë‹µ í´ë˜ìŠ¤ í™•ë¥  (p_t): {pt}")
    print(f"4. ì •ë‹µ í´ë˜ìŠ¤ log í™•ë¥  (log p_t): {log_pt}\n")
    
    # 4. Focal Loss ê³„ì‚° (Î±=1.0, Î³=2.0)
    alpha = 1.0
    gamma = 2.0
    
    # ìˆ˜ë™ ê³„ì‚°
    focal_weight = (1 - pt) ** gamma
    focal_loss_manual = -alpha * focal_weight * log_pt
    
    print(f"5. Focal ê°€ì¤‘ì¹˜ (1 - p_t)^Î³:\n{focal_weight}")
    print(f"6. ìµœì¢… Focal Loss (-Î± * (1 - p_t)^Î³ * log(p_t)):\n{focal_loss_manual}")
    print(f"7. í‰ê·  Focal Loss: {focal_loss_manual.mean():.4f}\n")
    
    # 5. CrossEntropyì™€ ë¹„êµ
    ce_loss = F.cross_entropy(logits, targets)
    print(f"ğŸ“ˆ CrossEntropy Loss: {ce_loss:.4f}")
    print(f"ğŸ“ˆ Focal Loss (í‰ê· ): {focal_loss_manual.mean():.4f}")
    print(f"ğŸ“ˆ ë¹„ìœ¨ (Focal/CE): {(focal_loss_manual.mean() / ce_loss):.4f}\n")
    
    # 6. ê° ìƒ˜í”Œë³„ ë¶„ì„
    print("ğŸ”¬ ìƒ˜í”Œë³„ ë¶„ì„:")
    for i in range(batch_size):
        p_t = pt[i].item()
        ce_sample = -log_pt[i].item()
        focal_sample = focal_loss_manual[i].item()
        weight = focal_weight[i].item()
        
        print(f"ìƒ˜í”Œ {i}:")
        print(f"  - ì •ë‹µ í™•ë¥  (p_t): {p_t:.4f}")
        print(f"  - CrossEntropy: {ce_sample:.4f}")
        print(f"  - Focal ê°€ì¤‘ì¹˜: {weight:.4f}")
        print(f"  - Focal Loss: {focal_sample:.4f}")
        print(f"  - ê°€ì¤‘ì¹˜ íš¨ê³¼: {'ê°ì†Œ' if p_t > 0.5 else 'ì¦ê°€'}")
        print()
    
    # 7. êµ¬í˜„ ê²€ì¦
    print("âœ… êµ¬í˜„ ê²€ì¦:")
    
    # í˜„ì¬ êµ¬í˜„ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ê³„ì‚°
    class FocalLoss(torch.nn.Module):
        def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):
            super().__init__()
            self.alpha = alpha
            self.gamma = gamma
            self.reduction = reduction

        def forward(self, inputs, targets):
            log_probs = F.log_softmax(inputs, dim=1)
            probs = torch.exp(log_probs)
            targets = targets.long()
            pt = probs.gather(1, targets.unsqueeze(1)).squeeze(1)
            log_pt = log_probs.gather(1, targets.unsqueeze(1)).squeeze(1)
            loss = -self.alpha * (1 - pt) ** self.gamma * log_pt
            
            if self.reduction == 'mean':
                return loss.mean()
            else:
                return loss.sum()
    
    focal_loss_fn = FocalLoss(alpha=alpha, gamma=gamma)
    focal_loss_result = focal_loss_fn(logits, targets)
    
    print(f"  - ìˆ˜ë™ ê³„ì‚° ê²°ê³¼: {focal_loss_manual.mean():.6f}")
    print(f"  - í•¨ìˆ˜ ê³„ì‚° ê²°ê³¼: {focal_loss_result:.6f}")
    print(f"  - ì¼ì¹˜ ì—¬ë¶€: {'âœ… ì¼ì¹˜' if abs(focal_loss_manual.mean() - focal_loss_result) < 1e-6 else 'âŒ ë¶ˆì¼ì¹˜'}")
    
    # 8. ìˆ˜ì‹ ê²€ì¦
    print("\nğŸ“ ìˆ˜ì‹ ê²€ì¦:")
    print("ì›ë˜ ìˆ˜ì‹: FL(p_t) = -Î± * (1 - p_t)^Î³ * log(p_t)")
    
    # ê° ìƒ˜í”Œì— ëŒ€í•´ ìˆ˜ì‹ ê²€ì¦
    for i in range(batch_size):
        p_t = pt[i].item()
        log_p_t = log_pt[i].item()
        alpha_val = alpha
        gamma_val = gamma
        
        # ìˆ˜ì‹ì— ë”°ë¥¸ ê³„ì‚°
        focal_formula = -alpha_val * ((1 - p_t) ** gamma_val) * log_p_t
        focal_actual = focal_loss_manual[i].item()
        
        print(f"ìƒ˜í”Œ {i}:")
        print(f"  - p_t = {p_t:.4f}")
        print(f"  - log(p_t) = {log_p_t:.4f}")
        print(f"  - (1 - p_t)^Î³ = {(1 - p_t) ** gamma_val:.4f}")
        print(f"  - ìˆ˜ì‹ ê²°ê³¼: {focal_formula:.6f}")
        print(f"  - ì‹¤ì œ ê²°ê³¼: {focal_actual:.6f}")
        print(f"  - ê²€ì¦: {'âœ… í†µê³¼' if abs(focal_formula - focal_actual) < 1e-6 else 'âŒ ì‹¤íŒ¨'}")
        print()
    
    # 9. íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê²€ì¦
    print("ğŸ¯ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê²€ì¦:")
    
    # ë§¤ìš° í™•ì‹¤í•œ ì˜ˆì¸¡ (p_t â‰ˆ 1)
    confident_logits = torch.tensor([[5.0, 0.1]], dtype=torch.float32)
    confident_targets = torch.tensor([0], dtype=torch.long)
    
    confident_focal = focal_loss_fn(confident_logits, confident_targets)
    confident_ce = F.cross_entropy(confident_logits, confident_targets)
    
    print(f"í™•ì‹¤í•œ ì˜ˆì¸¡ (p_t â‰ˆ 1):")
    print(f"  - CrossEntropy: {confident_ce:.6f}")
    print(f"  - Focal Loss: {confident_focal:.6f}")
    print(f"  - ê°ì†Œìœ¨: {(1 - confident_focal/confident_ce)*100:.2f}%")
    
    # ë§¤ìš° ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡ (p_t â‰ˆ 0.5)
    uncertain_logits = torch.tensor([[0.1, 0.1]], dtype=torch.float32)
    uncertain_targets = torch.tensor([0], dtype=torch.long)
    
    uncertain_focal = focal_loss_fn(uncertain_logits, uncertain_targets)
    uncertain_ce = F.cross_entropy(uncertain_logits, uncertain_targets)
    
    print(f"\në¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡ (p_t â‰ˆ 0.5):")
    print(f"  - CrossEntropy: {uncertain_ce:.6f}")
    print(f"  - Focal Loss: {uncertain_focal:.6f}")
    print(f"  - ì¦ê°€ìœ¨: {(uncertain_focal/uncertain_ce - 1)*100:.2f}%")
    
    print("\nâœ… Focal Loss êµ¬í˜„ì´ ì›ë˜ ìˆ˜ì‹ê³¼ ì •í™•íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!")

if __name__ == "__main__":
    check_focal_loss_implementation() 