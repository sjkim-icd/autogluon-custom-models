import torch
import torch.nn.functional as F
import numpy as np

def test_corrected_focal_loss():
    """ìˆ˜ì •ëœ Focal Loss êµ¬í˜„ í…ŒìŠ¤íŠ¸"""
    print("=== ìˆ˜ì •ëœ Focal Loss êµ¬í˜„ í…ŒìŠ¤íŠ¸ ===\n")
    
    # ìˆ˜ì •ëœ Focal Loss í´ë˜ìŠ¤
    class CorrectedFocalLoss(torch.nn.Module):
        def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):
            super().__init__()
            self.alpha = alpha
            self.gamma = gamma
            self.reduction = reduction

        def forward(self, inputs, targets):
            log_probs = F.log_softmax(inputs, dim=1)
            probs = torch.exp(log_probs)
            targets = targets.long()
            pt = probs.gather(1, targets.unsqueeze(1)).squeeze(1)
            log_pt = log_probs.gather(1, targets.unsqueeze(1)).squeeze(1)
            
            # ë…¼ë¬¸ ìˆ˜ì‹: Î±_t ì ìš©
            alpha_t = torch.where(targets == 1, self.alpha, 1 - self.alpha)
            loss = -alpha_t * (1 - pt) ** self.gamma * log_pt
            
            if self.reduction == 'mean':
                return loss.mean()
            else:
                return loss.sum()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    logits = torch.tensor([
        [2.0, 1.0],  # Class 0ì— ë†’ì€ í™•ì‹ 
        [1.0, 2.0],  # Class 1ì— ë†’ì€ í™•ì‹   
        [0.5, 0.5],  # ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡
        [0.1, 3.0]   # Class 1ì— ë§¤ìš° ë†’ì€ í™•ì‹ 
    ], dtype=torch.float32)
    
    targets = torch.tensor([0, 1, 0, 1], dtype=torch.long)
    
    print(f"ì…ë ¥ ë¡œì§“:\n{logits}")
    print(f"ì •ë‹µ ë¼ë²¨: {targets}")
    print(f"  (0: negative class, 1: positive class)\n")
    
    # ë…¼ë¬¸ ê¶Œì¥ íŒŒë¼ë¯¸í„°ë¡œ í…ŒìŠ¤íŠ¸
    alpha = 0.25  # positive class ê°€ì¤‘ì¹˜
    gamma = 2.0   # focusing parameter
    
    # ìˆ˜ì •ëœ Focal Loss í…ŒìŠ¤íŠ¸
    corrected_focal = CorrectedFocalLoss(alpha=alpha, gamma=gamma)
    corrected_result = corrected_focal(logits, targets)
    
    print(f"ğŸ“Š ìˆ˜ì •ëœ Focal Loss ê²°ê³¼:")
    print(f"  - Î± = {alpha}, Î³ = {gamma}")
    print(f"  - í‰ê·  ì†ì‹¤: {corrected_result:.6f}")
    
    # ë‹¨ê³„ë³„ ê³„ì‚°ìœ¼ë¡œ ê²€ì¦
    log_probs = F.log_softmax(logits, dim=1)
    probs = torch.exp(log_probs)
    pt = probs.gather(1, targets.unsqueeze(1)).squeeze(1)
    log_pt = log_probs.gather(1, targets.unsqueeze(1)).squeeze(1)
    alpha_t = torch.where(targets == 1, alpha, 1 - alpha)
    focal_weight = (1 - pt) ** gamma
    manual_result = (-alpha_t * focal_weight * log_pt).mean()
    
    print(f"\nğŸ” ìˆ˜ë™ ê³„ì‚° ê²€ì¦:")
    print(f"  - ìˆ˜ë™ ê³„ì‚° ê²°ê³¼: {manual_result:.6f}")
    print(f"  - í•¨ìˆ˜ ê³„ì‚° ê²°ê³¼: {corrected_result:.6f}")
    print(f"  - ì¼ì¹˜ ì—¬ë¶€: {'âœ… ì¼ì¹˜' if abs(manual_result - corrected_result) < 1e-6 else 'âŒ ë¶ˆì¼ì¹˜'}")
    
    # ê° ìƒ˜í”Œë³„ ìƒì„¸ ë¶„ì„
    print(f"\nğŸ“ˆ ìƒ˜í”Œë³„ ìƒì„¸ ë¶„ì„:")
    for i in range(len(targets)):
        target = targets[i].item()
        p_t = pt[i].item()
        alpha_t_val = alpha_t[i].item()
        focal_weight_val = focal_weight[i].item()
        loss_val = (-alpha_t[i] * focal_weight[i] * log_pt[i]).item()
        
        print(f"ìƒ˜í”Œ {i}:")
        print(f"  - ì •ë‹µ í´ë˜ìŠ¤: {target} ({'positive' if target == 1 else 'negative'})")
        print(f"  - ì •ë‹µ í™•ë¥  (p_t): {p_t:.4f}")
        print(f"  - Î±_t: {alpha_t_val:.2f}")
        print(f"  - Focal ê°€ì¤‘ì¹˜ (1 - p_t)^Î³: {focal_weight_val:.4f}")
        print(f"  - ì†ì‹¤: {loss_val:.6f}")
        print()
    
    # CrossEntropyì™€ ë¹„êµ
    ce_loss = F.cross_entropy(logits, targets)
    print(f"ğŸ“Š ì†ì‹¤ ë¹„êµ:")
    print(f"  - CrossEntropy Loss: {ce_loss:.6f}")
    print(f"  - ìˆ˜ì •ëœ Focal Loss: {corrected_result:.6f}")
    print(f"  - ë¹„ìœ¨ (Focal/CE): {(corrected_result / ce_loss):.2f}")
    
    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ¯ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸:")
    
    # ë§¤ìš° í™•ì‹¤í•œ ì˜ˆì¸¡ (p_t â‰ˆ 1)
    confident_logits = torch.tensor([[5.0, 0.1]], dtype=torch.float32)
    confident_targets = torch.tensor([0], dtype=torch.long)
    
    confident_focal = corrected_focal(confident_logits, confident_targets)
    confident_ce = F.cross_entropy(confident_logits, confident_targets)
    
    print(f"í™•ì‹¤í•œ ì˜ˆì¸¡ (p_t â‰ˆ 1):")
    print(f"  - CrossEntropy: {confident_ce:.6f}")
    print(f"  - ìˆ˜ì •ëœ Focal Loss: {confident_focal:.6f}")
    print(f"  - ê°ì†Œìœ¨: {(1 - confident_focal/confident_ce)*100:.2f}%")
    
    # ë§¤ìš° ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡ (p_t â‰ˆ 0.5)
    uncertain_logits = torch.tensor([[0.1, 0.1]], dtype=torch.float32)
    uncertain_targets = torch.tensor([0], dtype=torch.long)
    
    uncertain_focal = corrected_focal(uncertain_logits, uncertain_targets)
    uncertain_ce = F.cross_entropy(uncertain_logits, uncertain_targets)
    
    print(f"\në¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡ (p_t â‰ˆ 0.5):")
    print(f"  - CrossEntropy: {uncertain_ce:.6f}")
    print(f"  - ìˆ˜ì •ëœ Focal Loss: {uncertain_focal:.6f}")
    print(f"  - ì¦ê°€ìœ¨: {(uncertain_focal/uncertain_ce - 1)*100:.2f}%")
    
    print(f"\nâœ… ìˆ˜ì •ëœ Focal Loss êµ¬í˜„ì´ ë…¼ë¬¸ ì›ë³¸ ìˆ˜ì‹ê³¼ ì •í™•íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!")
    print(f"âœ… Î±_t ì ìš©ìœ¼ë¡œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ ë” íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤!")

if __name__ == "__main__":
    test_corrected_focal_loss() 