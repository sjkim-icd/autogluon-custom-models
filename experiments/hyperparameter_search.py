import pandas as pd
import numpy as np
from autogluon.tabular import TabularPredictor
import os
import sys

# ì»¤ìŠ¤í…€ ëª¨ë¸ import
sys.path.append('.')
from custom_models.tabular_dcnv2_torch_model import TabularDCNv2TorchModel
from custom_models.focal_loss_implementation import CustomFocalDLModel
from custom_models.custom_nn_torch_model import CustomNNTorchModel

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print("=== ë°ì´í„° ë¡œë“œ ===")
    
    # Credit Card Fraud Detection ë°ì´í„°ì…‹ ë¡œë“œ
    data = pd.read_csv('creditcard.csv')
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    train_data = data.iloc[:-56962]  # ë§ˆì§€ë§‰ 56962ê°œë¥¼ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©
    test_data = data.iloc[-56962:]
    
    print(f"í•™ìŠµ ë°ì´í„° í¬ê¸°: {train_data.shape}")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {test_data.shape}")
    print(f"í•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬:\n{train_data['Class'].value_counts()}")
    print(f"í•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¹„ìœ¨:\n{train_data['Class'].value_counts(normalize=True)}")
    
    return train_data, test_data

def register_custom_models():
    """ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡"""
    print("=== ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡ ===")
    
    # DCNv2 ë“±ë¡
    TabularDCNv2TorchModel.register()
    
    # CustomFocalDLModel ë“±ë¡
    CustomFocalDLModel.register()
    
    # CustomNNTorchModel ë“±ë¡
    CustomNNTorchModel.register()
    
    print("âœ… ëª¨ë“  ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡ ì™„ë£Œ")

def create_hyperparameter_configs():
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ì„ ìœ„í•œ ë‹¤ì–‘í•œ ì„¤ì • ìƒì„±"""
    
    configs = {
        # === DCNv2 í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ===
        "DCNV2_SEARCH": [
            # ê¸°ë³¸ ì„¤ì •
            {
                "num_cross_layers": 2,
                "cross_dropout": 0.1,
                "low_rank": 16,
                "deep_output_size": 64,
                "deep_hidden_size": 64,
                "deep_dropout": 0.1,
                "deep_layers": 2,
                'epochs_wo_improve': 5,
                'num_epochs': 20,
                "lr_scheduler": True,
                "scheduler_type": "cosine",
                "lr_scheduler_min_lr": 1e-6,
                "learning_rate": 0.0001,
            },
            # ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬
            {
                "num_cross_layers": 3,
                "cross_dropout": 0.2,
                "low_rank": 32,
                "deep_output_size": 128,
                "deep_hidden_size": 128,
                "deep_dropout": 0.2,
                "deep_layers": 3,
                'epochs_wo_improve': 5,
                'num_epochs': 20,
                "lr_scheduler": True,
                "scheduler_type": "cosine",
                "lr_scheduler_min_lr": 1e-6,
                "learning_rate": 0.0001,
            },
            # ë” ë†’ì€ í•™ìŠµë¥ 
            {
                "num_cross_layers": 2,
                "cross_dropout": 0.1,
                "low_rank": 16,
                "deep_output_size": 64,
                "deep_hidden_size": 64,
                "deep_dropout": 0.1,
                "deep_layers": 2,
                'epochs_wo_improve': 5,
                'num_epochs': 20,
                "lr_scheduler": True,
                "scheduler_type": "cosine",
                "lr_scheduler_min_lr": 1e-6,
                "learning_rate": 0.001,
            },
        ],
        
        # === CustomFocalDL í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ===
        "CUSTOM_FOCAL_DL_SEARCH": [
            # ê¸°ë³¸ ì„¤ì •
            {
                'max_batch_size': 512,
                'num_epochs': 20,
                'epochs_wo_improve': 5,
                'optimizer': 'adam',
                'learning_rate': 0.001,
                'weight_decay': 0.0001,
                'dropout_prob': 0.1,
                'num_layers': 4,
                'hidden_size': 128,
                'activation': 'relu',
                'lr_scheduler': True,
                'scheduler_type': 'cosine',
                'lr_scheduler_min_lr': 1e-6,
            },
            # ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬
            {
                'max_batch_size': 512,
                'num_epochs': 20,
                'epochs_wo_improve': 5,
                'optimizer': 'adam',
                'learning_rate': 0.001,
                'weight_decay': 0.0001,
                'dropout_prob': 0.2,
                'num_layers': 6,
                'hidden_size': 256,
                'activation': 'relu',
                'lr_scheduler': True,
                'scheduler_type': 'cosine',
                'lr_scheduler_min_lr': 1e-6,
            },
            # ë” ë‚®ì€ í•™ìŠµë¥ 
            {
                'max_batch_size': 512,
                'num_epochs': 20,
                'epochs_wo_improve': 5,
                'optimizer': 'adam',
                'learning_rate': 0.0001,
                'weight_decay': 0.0001,
                'dropout_prob': 0.1,
                'num_layers': 4,
                'hidden_size': 128,
                'activation': 'relu',
                'lr_scheduler': True,
                'scheduler_type': 'cosine',
                'lr_scheduler_min_lr': 1e-6,
            },
        ],
        
        # === CustomNNTorch í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ===
        "CUSTOM_NN_TORCH_SEARCH": [
            # ê¸°ë³¸ ì„¤ì •
            {
                'max_batch_size': 512,
                'num_epochs': 20,
                'epochs_wo_improve': 5,
                'optimizer': 'adam',
                'learning_rate': 0.001,
                'weight_decay': 0.0001,
                'dropout_prob': 0.1,
                'num_layers': 4,
                'hidden_size': 128,
                'activation': 'relu',
                'lr_scheduler': True,
                'scheduler_type': 'cosine',
                'lr_scheduler_min_lr': 1e-6,
            },
            # ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬
            {
                'max_batch_size': 512,
                'num_epochs': 20,
                'epochs_wo_improve': 5,
                'optimizer': 'adam',
                'learning_rate': 0.001,
                'weight_decay': 0.0001,
                'dropout_prob': 0.2,
                'num_layers': 6,
                'hidden_size': 256,
                'activation': 'relu',
                'lr_scheduler': True,
                'scheduler_type': 'cosine',
                'lr_scheduler_min_lr': 1e-6,
            },
            # SGD ì˜µí‹°ë§ˆì´ì €
            {
                'max_batch_size': 512,
                'num_epochs': 20,
                'epochs_wo_improve': 5,
                'optimizer': 'sgd',
                'learning_rate': 0.01,
                'weight_decay': 0.0001,
                'dropout_prob': 0.1,
                'num_layers': 4,
                'hidden_size': 128,
                'activation': 'relu',
                'lr_scheduler': True,
                'scheduler_type': 'cosine',
                'lr_scheduler_min_lr': 1e-6,
            },
        ],
    }
    
    return configs

def run_hyperparameter_search():
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ì‹¤í–‰"""
    print("=== í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ì‹œì‘ ===")
    
    # ë°ì´í„° ë¡œë“œ
    train_data, test_data = load_data()
    
    # ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡
    register_custom_models()
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ìƒì„±
    configs = create_hyperparameter_configs()
    
    results = []
    
    # ê° ëª¨ë¸ë³„ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰
    for model_name, model_configs in configs.items():
        print(f"\n=== {model_name} í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ===")
        
        for i, config in enumerate(model_configs):
            print(f"\n--- ì„¤ì • {i+1}/{len(model_configs)} ---")
            print(f"ì„¤ì •: {config}")
            
            # ëª¨ë¸ëª… ìƒì„±
            current_model_name = f"{model_name}_config_{i+1}"
            
            # ì˜ˆì¸¡ê¸° ìƒì„±
            predictor = TabularPredictor(
                label='Class',
                eval_metric='f1',
                path=f"models/hyperparameter_search/{current_model_name}",
                verbosity=2  # ë¡œê·¸ ë ˆë²¨ ë‚®ì¶¤
            )
            
            try:
                # AutoGluon ë°©ì‹ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ë‹¬
                if model_name == "DCNV2_SEARCH":
                    hyperparameters = {
                        "DCNV2": [config]
                    }
                elif model_name == "CUSTOM_FOCAL_DL_SEARCH":
                    hyperparameters = {
                        "CUSTOM_FOCAL_DL": [config]
                    }
                elif model_name == "CUSTOM_NN_TORCH_SEARCH":
                    hyperparameters = {
                        "CUSTOM_NN_TORCH": [config]
                    }
                
                # í•™ìŠµ ì‹¤í–‰
                predictor.fit(
                    train_data=train_data,
                    hyperparameters=hyperparameters,
                    time_limit=300,  # 5ë¶„ ì œí•œ
                    verbosity=2
                )
                
                # ì„±ëŠ¥ í‰ê°€
                leaderboard = predictor.leaderboard()
                best_score = leaderboard.iloc[0]['score_val']
                fit_time = leaderboard.iloc[0]['fit_time_marginal']
                
                print(f"âœ… ì„±ëŠ¥: {best_score:.4f}, í•™ìŠµì‹œê°„: {fit_time:.2f}ì´ˆ")
                
                # ê²°ê³¼ ì €ì¥
                results.append({
                    'model_name': current_model_name,
                    'config': config,
                    'f1_score': best_score,
                    'fit_time': fit_time,
                    'config_num': i+1
                })
                
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                results.append({
                    'model_name': current_model_name,
                    'config': config,
                    'f1_score': 0.0,
                    'fit_time': 0.0,
                    'config_num': i+1,
                    'error': str(e)
                })
    
    # ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥
    print("\n=== í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê²°ê³¼ ===")
    results_df = pd.DataFrame(results)
    
    # ì„±ê³µí•œ ì‹¤í—˜ë§Œ í•„í„°ë§
    successful_results = results_df[results_df['f1_score'] > 0]
    
    if len(successful_results) > 0:
        print("\nğŸ“Š ì„±ê³µí•œ ì‹¤í—˜ ê²°ê³¼:")
        for _, row in successful_results.iterrows():
            print(f"{row['model_name']}: F1={row['f1_score']:.4f}, ì‹œê°„={row['fit_time']:.2f}ì´ˆ")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        best_model = successful_results.loc[successful_results['f1_score'].idxmax()]
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model['model_name']}")
        print(f"F1 Score: {best_model['f1_score']:.4f}")
        print(f"í•™ìŠµ ì‹œê°„: {best_model['fit_time']:.2f}ì´ˆ")
        print(f"ì„¤ì •: {best_model['config']}")
    
    # ì „ì²´ ê²°ê³¼ ì €ì¥
    results_df.to_csv('experiments/hyperparameter_search_results.csv', index=False)
    print(f"\nğŸ“ ê²°ê³¼ê°€ 'experiments/hyperparameter_search_results.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return results_df

if __name__ == "__main__":
    run_hyperparameter_search() 