import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
import ray
from autogluon.tabular import TabularPredictor
from autogluon.tabular.registry import ag_model_registry
from custom_models.tabular_dcnv2_torch_model import TabularDCNv2TorchModel
from custom_models.focal_loss_implementation import CustomFocalDLModel
from custom_models.custom_nn_torch_model import CustomNNTorchModel
from sklearn.model_selection import train_test_split
from autogluon.common import space

# Ray ì´ˆê¸°í™”
# ray.init(num_cpus=2, ignore_reinit_error=True)

# ëª¨ë¸ ë“±ë¡
ag_model_registry.add(TabularDCNv2TorchModel)
ag_model_registry.add(CustomFocalDLModel)
ag_model_registry.add(CustomNNTorchModel)

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print("=== ë°ì´í„° ë¡œë“œ ===")
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv("datasets/creditcard.csv")
    df["Class"] = df["Class"].astype("category")  # AutoGluonì—ì„œ ë¶„ë¥˜ë¡œ ì¸ì‹í•˜ê²Œ

    # í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
    train_data, test_data = train_test_split(df, test_size=0.2, stratify=df["Class"], random_state=42)
    
    print(f"í•™ìŠµ ë°ì´í„° í¬ê¸°: {train_data.shape}")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {test_data.shape}")
    print(f"í•™ìŠµ ë°ì´í„° í´ëž˜ìŠ¤ ë¶„í¬:\n{train_data['Class'].value_counts()}")
    print(f"í•™ìŠµ ë°ì´í„° í´ëž˜ìŠ¤ ë¹„ìœ¨:\n{train_data['Class'].value_counts(normalize=True)}")
    
    return train_data, test_data

def register_custom_models():
    """ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡"""
    print("=== ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡ ===")
    
    # DCNv2 ëª¨ë¸ ë“±ë¡ í™•ì¸
    from custom_models.tabular_dcnv2_torch_model import TabularDCNv2TorchModel
    from autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch import TabularNeuralNetTorchModel
    
    # ëª¨ë¸ì´ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸
    if ag_model_registry.exists(TabularDCNv2TorchModel):
        print("âœ… DCNv2 ëª¨ë¸ì´ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìžˆìŒ")
    else:
        ag_model_registry.add(TabularDCNv2TorchModel)
        print("âœ… DCNv2 ëª¨ë¸ ë“±ë¡ ì™„ë£Œ")

def run_hyperparameter_search():
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ì‹¤í–‰ - AutoGluon í˜•ì‹ [,,] ì‚¬ìš©"""
    print("=== í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ì‹œìž‘ (AutoGluon í˜•ì‹) ===")
    
    # ë°ì´í„° ë¡œë“œ
    train_data, test_data = load_data()
    
    # ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡
    register_custom_models()
    
    # AutoGluon í˜•ì‹ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • - fit() ì•ˆì—ì„œ ì§ì ‘ ì „ë‹¬
    print("=== í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê³µê°„ ===")
    print("DCNv2: ê°œë³„ íŒŒë¼ë¯¸í„°ë³„ ê²€ìƒ‰ (cross_layers, dropout, learning_rate ë“±)")
    print("CustomFocalDL: ê°œë³„ íŒŒë¼ë¯¸í„°ë³„ ê²€ìƒ‰ (layers, hidden_size, learning_rate ë“±)")
    print("CustomNNTorch: ê°œë³„ íŒŒë¼ë¯¸í„°ë³„ ê²€ìƒ‰ (optimizer, layers, learning_rate ë“±)")
    print("RandomForest: ê°œë³„ íŒŒë¼ë¯¸í„°ë³„ ê²€ìƒ‰ (n_estimators, max_depth, criterion ë“±)")
    print("ì´ 4ê°œ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸")
    print("ì œí•œëœ ë³‘ë ¬ ì²˜ë¦¬: 2ê°œ CPU ì½”ì–´ ì‚¬ìš© (ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ)")
    
    # ì˜ˆì¸¡ê¸° ìƒì„±
    predictor = TabularPredictor(
        label='Class',
        eval_metric='f1'
        # path="models/hyperparameter_search_autogluon",
        # verbosity=5  # HPOì—ì„œ epoch ë¡œê·¸ë¥¼ ë³´ê¸° ìœ„í•´ ë†’ì€ verbosity
    )
    
    # í•™ìŠµ ì‹¤í–‰ - AutoGluon í˜•ì‹ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ë‹¬ (ì œí•œëœ ë³‘ë ¬ ì²˜ë¦¬)
    print("\n=== AutoGluon í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ì‹œìž‘ (ì œí•œëœ ë³‘ë ¬ ì²˜ë¦¬) ===")
    predictor.fit(
        train_data=train_data,
        hyperparameters={
            # DCNv2 í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê³µê°„ - ê°œë³„ íŒŒë¼ë¯¸í„°ë³„ë¡œ []
            "DCNV2": {
                "num_cross_layers": space.Int(2, 3, default=2),
                "cross_dropout": space.Real(0.1, 0.2, default=0.1),
                "low_rank": space.Int(16, 32, default=16),
                "deep_output_size": space.Int(64, 128, default=64),
                "deep_hidden_size": space.Int(64, 128, default=64),
                "deep_dropout": space.Real(0.1, 0.2, default=0.1),
                "deep_layers": space.Int(2, 3, default=2),
                "learning_rate": space.Real(0.0001, 0.001, default=0.0001),
            },
            
            # CustomFocalDL í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê³µê°„ - space í˜•íƒœë¡œ ì •ì˜
            "CUSTOM_FOCAL_DL": {
                # ê³ ì •ê°’ë“¤ (HPOì—ì„œ ì œì™¸) - í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
                # 'max_batch_size': space.Int(512, 512, default=512),
                # 'num_epochs': space.Int(20, 20, default=20),
                # 'epochs_wo_improve': space.Int(5, 5, default=5),
                # 'optimizer': space.Categorical('adam'),
                # 'weight_decay': space.Real(0.0001, 0.0001, default=0.0001),
                # 'lr_scheduler': space.Categorical(True),
                # 'scheduler_type': space.Categorical('cosine'),
                # 'lr_scheduler_min_lr': space.Real(1e-6, 1e-6, default=1e-6),
                
                # íŠœë‹ ëŒ€ìƒ íŒŒë¼ë¯¸í„°ë“¤
                'learning_rate': space.Real(0.0001, 0.001, default=0.0001),
                'dropout_prob': space.Real(0.1, 0.2, default=0.1),
                'num_layers': space.Int(4, 6, default=4),
                'hidden_size': space.Int(128, 256, default=128),
                'activation': space.Categorical('relu'),
            },
            
            # # CustomNNTorch í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê³µê°„ - space í˜•íƒœë¡œ ì •ì˜
            "CUSTOM_NN_TORCH": {
                # ê³ ì •ê°’ë“¤ (HPOì—ì„œ ì œì™¸) - í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
                # 'max_batch_size': space.Int(512, 512, default=512),
                # 'num_epochs': space.Int(20, 20, default=20),
                # 'epochs_wo_improve': space.Int(5, 5, default=5),
                # 'weight_decay': space.Real(0.0001, 0.0001, default=0.0001),
                # 'lr_scheduler': space.Categorical(True),
                # 'scheduler_type': space.Categorical('cosine'),
                # 'lr_scheduler_min_lr': space.Real(1e-6, 1e-6, default=1e-6),
                
                # íŠœë‹ ëŒ€ìƒ íŒŒë¼ë¯¸í„°ë“¤
                'optimizer': space.Categorical('adam', 'sgd'),
                'learning_rate': space.Real(0.001, 0.01, default=0.001),
                'dropout_prob': space.Real(0.1, 0.2, default=0.1),
                'num_layers': space.Int(4, 6, default=4),
                'hidden_size': space.Int(128, 256, default=128),
                'activation': space.Categorical('relu'),
            },
            
            # RandomForest í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê³µê°„ - space í˜•íƒœë¡œ ì •ì˜
            "RF": {
                "n_estimators": space.Int(100, 300, default=100),
                "max_depth": space.Int(10, 20, default=10),
                "min_samples_split": space.Int(2, 10, default=2),
                "min_samples_leaf": space.Int(1, 4, default=1),
                "criterion": space.Categorical("gini", "entropy"),
            },
        },
        # time_limit=180,  # 30ë¶„ ì œí•œ
        hyperparameter_tune_kwargs={
            'scheduler': 'local',
            'searcher': 'random',
            'num_trials': 20,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 2ë²ˆ ì‹œë„ë¡œ ì œí•œ
        },
        num_cpus=2,       # ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ 2ê°œ CPUë§Œ ì‚¬ìš©
        num_gpus=0,       # GPU ì—†ìŒ
        verbosity=5       # HPOì—ì„œ epoch ë¡œê·¸ë¥¼ ë³´ê¸° ìœ„í•´ ë†’ì€ verbosity
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n=== í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²€ìƒ‰ ê²°ê³¼ ===")
    leaderboard = predictor.leaderboard()
    print(leaderboard)
    
    # ìƒì„¸ ë¶„ì„
    print("\n=== ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„ ===")
    for idx, row in leaderboard.iterrows():
        model_name = row['model']
        score = row['score_val']
        fit_time = row['fit_time_marginal']
        print(f"\n{model_name}:")
        print(f"  - F1 Score: {score:.4f}")
        print(f"  - í•™ìŠµ ì‹œê°„: {fit_time:.2f}ì´ˆ")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
    best_row = leaderboard.loc[leaderboard['score_val'].idxmax()]
    print(f"\nðŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_row['model']}")
    print(f"F1 Score: {best_row['score_val']:.4f}")
    print(f"í•™ìŠµ ì‹œê°„: {best_row['fit_time_marginal']:.2f}ì´ˆ")
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„°ë³„ ì„±ëŠ¥ ë¹„êµ
    print("\n=== í•˜ì´í¼íŒŒë¼ë¯¸í„°ë³„ ì„±ëŠ¥ ë¹„êµ ===")
    for model_type in ['DCNV2', 'CUSTOM_FOCAL_DL', 'CUSTOM_NN_TORCH', 'RF']:
        model_results = leaderboard[leaderboard['model'].str.contains(model_type)]
        if len(model_results) > 0:
            print(f"\n{model_type} ê²°ê³¼:")
            for _, row in model_results.iterrows():
                print(f"  {row['model']}: F1={row['score_val']:.4f}, ì‹œê°„={row['fit_time_marginal']:.2f}ì´ˆ")
    
    # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    print("\n=== ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ===")
    predictions = predictor.predict(test_data)
    probabilities = predictor.predict_proba(test_data)
    
    print(f"ì˜ˆì¸¡ ê²°ê³¼ í˜•íƒœ: {predictions.shape}")
    print(f"í™•ë¥  ì˜ˆì¸¡ í˜•íƒœ: {probabilities.shape}")
    print(f"ì˜ˆì¸¡ê°’ ìƒ˜í”Œ: {predictions.head()}")
    print(f"í™•ë¥ ê°’ ìƒ˜í”Œ:\n{probabilities.head()}")
    
    return predictor, leaderboard

if __name__ == "__main__":
    run_hyperparameter_search() 