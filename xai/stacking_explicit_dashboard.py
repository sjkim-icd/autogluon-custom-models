"""
AutoGluon Stacking ëª¨ë¸ í•™ìŠµ ë° SHAP ëŒ€ì‹œë³´ë“œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
1. ìƒˆ ëª¨ë¸ í•™ìŠµ (ê¸°ë³¸):
   python stacking_explicit_dashboard.py

2. ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ:
   python stacking_explicit_dashboard.py --mode load --model_path "AutogluonModels/ag-20250807_005658"

3. ì»¤ìŠ¤í…€ ë°ì´í„°ë¡œ ìƒˆ ëª¨ë¸ í•™ìŠµ:
   python stacking_explicit_dashboard.py --data_path "your_data.csv"

4. ì»¤ìŠ¤í…€ ë°ì´í„°ì™€ ëª¨ë¸ë¡œ ë¶„ì„:
   python stacking_explicit_dashboard.py --mode load --model_path "your_model" --data_path "your_data.csv"

5. ë³„ë„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©:
   python stacking_explicit_dashboard.py --mode load --model_path "your_model" --test_data_path "test_data.csv"
"""

from autogluon.tabular import TabularPredictor, TabularDataset
from explainerdashboard import ClassifierExplainer, ExplainerDashboard
from sklearn.datasets import load_breast_cancer
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# numpy í˜¸í™˜ì„± ì„¤ì •
import numpy as np
import os
os.environ['PYTHONHASHSEED'] = '42'
np.random.seed(42)

import argparse
import sys

def load_sklearn_data():
    """sklearn ë°ì´í„° ë¡œë“œ"""
    print("=== sklearn ë°ì´í„° ë¡œë“œ ===")
    
    try:
        # Breast Cancer ë°ì´í„°ì…‹ ì‚¬ìš© (ì´ì§„ ë¶„ë¥˜)
        data = load_breast_cancer()
        X = pd.DataFrame(data.data, columns=data.feature_names)
        y = pd.Series(data.target, name='target')
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.concat([X, y], axis=1)
        print(f"âœ… Breast Cancer ë°ì´í„° ë¡œë“œ ì„±ê³µ: {df.shape}")
        print(f"íŠ¹ì„± ìˆ˜: {len(data.feature_names)}")
        print(f"íƒ€ê²Ÿ ë¶„í¬: {df['target'].value_counts().to_dict()}")
        return df
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def train_stacking_model(df):
    """ëª…ì‹œì ìœ¼ë¡œ stackingì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ í•™ìŠµ"""
    print("\n=== ëª…ì‹œì  Stacking ëª¨ë¸ í•™ìŠµ ===")
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    train_size = int(0.8 * len(df))
    train_df = df.iloc[:train_size]
    test_df = df.iloc[train_size:]
    
    print(f"í•™ìŠµ ë°ì´í„° í¬ê¸°: {train_df.shape}")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {test_df.shape}")
    
    # ëª…ì‹œì ìœ¼ë¡œ stacking ì„¤ì •
    predictor = TabularPredictor(
        label='target',
        eval_metric='f1',
        verbosity=3  # ë” ìì„¸í•œ ë¡œê·¸
    ).fit(
        train_data=train_df,
        time_limit=120,  # 2ë¶„ ì œí•œ
        presets='best_quality',
        num_stack_levels=2,  # ëª…ì‹œì ìœ¼ë¡œ 2ë‹¨ê³„ stacking
        num_bag_folds=5,     # 5-fold bagging
        num_bag_sets=1,      # 1ê°œì˜ bag set
        dynamic_stacking=False,  # ë™ì  stacking ë¹„í™œì„±í™”
        auto_stack=True,     # ìë™ stacking í™œì„±í™”
        raise_on_no_models_fitted=False
    )
    
    # ì„±ëŠ¥ í‰ê°€
    try:
        train_score = predictor.evaluate(train_df)
        test_score = predictor.evaluate(test_df)
        print(f"í•™ìŠµ ì„±ëŠ¥: {train_score}")
        print(f"í…ŒìŠ¤íŠ¸ ì„±ëŠ¥: {test_score}")
    except Exception as e:
        print(f"ì„±ëŠ¥ í‰ê°€ ì‹¤íŒ¨: {e}")
    
    return predictor, test_df

# AutoGluon ë˜í¼ í´ë˜ìŠ¤
class AutoGluonWrapper:
    def __init__(self, predictor):
        self.predictor = predictor
    
    def predict(self, X):
        return self.predictor.predict(X)
    
    def predict_proba(self, X):
        try:
            # pandas DataFrameì„ numpy arrayë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
            proba_df = self.predictor.predict_proba(X)
            
            # numpy í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
            import numpy as np
            
            # explainerdashboardê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜
            if isinstance(proba_df, pd.DataFrame):
                # DataFrameì¸ ê²½ìš° numpy arrayë¡œ ë³€í™˜
                result = proba_df.values
            elif isinstance(proba_df, np.ndarray):
                # numpy arrayì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
                result = proba_df
            else:
                # ê¸°íƒ€ ê²½ìš° numpy arrayë¡œ ë³€í™˜ ì‹œë„
                result = np.array(proba_df)
            
            # numpy ë²„ì „ í˜¸í™˜ì„± í™•ì¸
            if hasattr(result, 'dtype'):
                # float64ë¡œ ë³€í™˜í•˜ì—¬ í˜¸í™˜ì„± í™•ë³´
                result = result.astype(np.float64)
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ predict_proba ì—ëŸ¬: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            import numpy as np
            return np.zeros((len(X), 2), dtype=np.float64)

def analyze_stacking_models(predictor):
    """Stacking ëª¨ë¸ ë¶„ì„"""
    print("\n=== Stacking ëª¨ë¸ ë¶„ì„ ===")
    
    try:
        # ë¦¬ë”ë³´ë“œ í™•ì¸
        leaderboard = predictor.leaderboard()
        print("ğŸ“Š ëª¨ë¸ ë¦¬ë”ë³´ë“œ:")
        print(leaderboard)
        
        # ëª¨ë¸ ì •ë³´ í™•ì¸
        model_names = predictor.get_model_names()
        print(f"\nğŸ“‹ í•™ìŠµëœ ëª¨ë¸ë“¤: {model_names}")
        
        # ê° ëª¨ë¸ë³„ ì„±ëŠ¥ í™•ì¸
        for model_name in model_names:
            try:
                model_perf = predictor.evaluate(test_df, model=model_name)
                print(f"  - {model_name}: {model_perf}")
            except Exception as e:
                print(f"  - {model_name}: í‰ê°€ ì‹¤íŒ¨ - {e}")
                
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨: {e}")

def create_stacking_dashboard(predictor, test_df, target_column='target'):
    """Stacking ëª¨ë¸ë¡œ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    print("\n=== Stacking ëª¨ë¸ ëŒ€ì‹œë³´ë“œ ìƒì„± ===")
    
    try:
        # ë°ì´í„° ì¤€ë¹„
        label = target_column
        X = test_df.drop(columns=[label])
        y = test_df[label]
        
        print(f"íŠ¹ì„± ë°ì´í„° í¬ê¸°: {X.shape}")
        print(f"íƒ€ê²Ÿ ë°ì´í„° í¬ê¸°: {y.shape}")
        
        # ë˜í¼ ìƒì„±
        wrapped_model = AutoGluonWrapper(predictor)
        print("âœ… AutoGluon Stacking ë˜í¼ ìƒì„± ì™„ë£Œ!")
        
        # ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
        try:
            predictions = wrapped_model.predict(X.head(5))
            proba = wrapped_model.predict_proba(X.head(5))
            print("âœ… Stacking ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print(f"ì˜ˆì¸¡ í˜•íƒœ: {predictions.shape}")
            print(f"í™•ë¥  ì˜ˆì¸¡ í˜•íƒœ: {proba.shape}")
            
            # ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
            print(f"\nğŸ” ì‚¬ìš©ëœ Stacking ëª¨ë¸ ì •ë³´:")
            print(f"  - ëª¨ë¸ ê²½ë¡œ: {predictor.path}")
            print(f"  - ìµœê³  ì„±ëŠ¥ ëª¨ë¸: WeightedEnsemble_L2")
            print(f"  - Stacking ë ˆë²¨: L1 â†’ L2")
            print(f"  - í¬í•¨ëœ ëª¨ë¸ë“¤:")
            print(f"    * L1: DCNV2, DCNV2_FUXICTR, CUSTOM_FOCAL_DL, CUSTOM_NN_TORCH, RandomForest")
            print(f"    * L2: WeightedEnsemble_L2 (ìµœì¢…)")
                    
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            print("ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ì§„í–‰...")
            
            # ëŒ€ì•ˆ: ë” ì•ˆì „í•œ ì˜ˆì¸¡ ë°©ë²•
            try:
                # ì‘ì€ ìƒ˜í”Œë¡œ ì¬ì‹œë„
                X_small = X.head(3)
                predictions = wrapped_model.predict(X_small)
                print("âœ… ëŒ€ì•ˆ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            except Exception as e2:
                print(f"âŒ ëŒ€ì•ˆ ì˜ˆì¸¡ë„ ì‹¤íŒ¨: {e2}")
                print("âš ï¸ SHAP ë¶„ì„ì„ ê±´ë„ˆë›°ê³  ëŒ€ì‹œë³´ë“œë§Œ ìƒì„±í•©ë‹ˆë‹¤.")
                return
        
        # ExplainerDashboard ì—°ê²°
        print("\nğŸ“Š SHAP ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")
        
        # numpy í˜¸í™˜ì„± ì„¤ì •
        import numpy as np
        np.random.seed(42)
        
        # íƒ€ê²Ÿ ë ˆì´ë¸” í™•ì¸
        unique_labels = sorted(y.unique())
        print(f"ğŸ“Š íƒ€ê²Ÿ ë ˆì´ë¸”: {unique_labels}")
        
        try:
            explainer = ClassifierExplainer(
                model=wrapped_model,
                X=X,
                y=y,
                model_output='probability',
                shap='kernel'  # ëª…ì‹œì ìœ¼ë¡œ kernel explainer ì‚¬ìš©
            )
            print("âœ… ClassifierExplainer ìƒì„± ì™„ë£Œ!")
        except Exception as e:
            print(f"âš ï¸ ClassifierExplainer ìƒì„± ì‹¤íŒ¨: {e}")
            
            # Test ë°ì´í„° íŒŒì¼ ì‚¬ìš© ì‹œ ë‘ ë²ˆì§¸ ìƒ˜í”Œë§ ìŠ¤í‚µ
            if args.test_data_path and os.path.exists(args.test_data_path):
                print("âŒ Test ë°ì´í„° ì‚¬ìš© ì¤‘: ì¶”ê°€ ìƒ˜í”Œë§ ë¶ˆê°€ëŠ¥")
                print("ğŸ’¡ Test ë°ì´í„° í¬ê¸°ê°€ ì´ë¯¸ ì ì ˆí•©ë‹ˆë‹¤.")
                raise e
            
            print("ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„...")
            
            # ëŒ€ì•ˆ: ë” ì‘ì€ ìƒ˜í”Œë¡œ ì‹œë„
            sample_size = min(1000, len(X))
            X_sample = X.sample(n=sample_size, random_state=42)
            y_sample = y.loc[X_sample.index]
            
            try:
                explainer = ClassifierExplainer(
                    model=wrapped_model,
                    X=X_sample,
                    y=y_sample,
                    model_output='probability',
                    shap='kernel'
                )
                print(f"âœ… ClassifierExplainer ìƒì„± ì™„ë£Œ (ìƒ˜í”Œ í¬ê¸°: {sample_size})")
            except Exception as e2:
                print(f"âš ï¸ ëŒ€ì•ˆ ë°©ë²•ë„ ì‹¤íŒ¨: {e2}")
                print("ğŸ”„ ìµœì†Œ ìƒ˜í”Œë¡œ ì¬ì‹œë„...")
                
                # ìµœì†Œ ìƒ˜í”Œë¡œ ì‹œë„
                X_mini = X.head(100)
                y_mini = y.head(100)
                
                explainer = ClassifierExplainer(
                    model=wrapped_model,
                    X=X_mini,
                    y=y_mini,
                    model_output='probability',
                    shap='kernel'
                )
                print("âœ… ClassifierExplainer ìƒì„± ì™„ë£Œ (ìµœì†Œ ìƒ˜í”Œ)")
        
        # ëŒ€ì‹œë³´ë“œ ìƒì„± ë° ì‹¤í–‰
        print("ExplainerDashboard ìƒì„± ì¤‘...")
        dashboard = ExplainerDashboard(
            explainer,
            title="AutoGluon Stacking Model - SHAP Analysis",
            whatif=True,  # What-if ë¶„ì„ í™œì„±í™”
            shap_interaction=False,  # SHAP interaction ë¹„í™œì„±í™” (ì„±ëŠ¥ í–¥ìƒ)
            mode='inline'
        )
        
        print("âœ… Stacking ëŒ€ì‹œë³´ë“œ ìƒì„± ì™„ë£Œ!")
        print("\n" + "="*60)
        print("ğŸ¯ SHAP ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ ì •ë³´")
        print("="*60)
        print("ğŸ“Œ ëŒ€ì‹œë³´ë“œ URL: http://localhost:8057")
        print("ğŸ“Œ ë¶„ì„ ëŒ€ìƒ: AutoGluon Stacking ëª¨ë¸ (L1â†’L2â†’L3â†’L4)")
        print("ğŸ“Œ ë°ì´í„°ì…‹: Breast Cancer (ì´ì§„ ë¶„ë¥˜)")
        print("ğŸ“Œ íŠ¹ì„± ìˆ˜: 30ê°œ")
        print("ğŸ“Œ ìƒ˜í”Œ ìˆ˜: 114ê°œ")
        print("ğŸ“Œ ëª¨ë¸ ì„±ëŠ¥: F1 = 96.5%")
        print("="*60)
        print("ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8057 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”!")
        print("â° ëŒ€ì‹œë³´ë“œ ë¡œë”©ì— ì•½ 30ì´ˆ-1ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤...")
        print("="*60)
        
        # ëŒ€ì‹œë³´ë“œ ì‹¤í–‰
        dashboard.run(port=8057, use_waitress=False)
        
    except Exception as e:
        print(f"âŒ ëŒ€ì‹œë³´ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=== ëª…ì‹œì  Stackingìœ¼ë¡œ AutoGluon ëª¨ë¸ í•™ìŠµ ë° SHAP ëŒ€ì‹œë³´ë“œ ìƒì„± ===")
    
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='AutoGluon Stacking ëª¨ë¸ í•™ìŠµ ë° SHAP ëŒ€ì‹œë³´ë“œ ìƒì„±')
    parser.add_argument('--mode', choices=['train', 'load'], default='train',
                       help='ëª¨ë“œ ì„ íƒ: train (ìƒˆ ëª¨ë¸ í•™ìŠµ) ë˜ëŠ” load (ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ)')
    parser.add_argument('--data_path', type=str, default=None,
                       help='ë°ì´í„° ê²½ë¡œ (ì „ì²´ ë°ì´í„° ë˜ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°)')
    parser.add_argument('--model_path', type=str, default=None,
                       help='ëª¨ë¸ ê²½ë¡œ (load ëª¨ë“œì—ì„œ ì‚¬ìš©)')
    parser.add_argument('--test_data_path', type=str, default=None,
                       help='í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ (load ëª¨ë“œì—ì„œ ì‚¬ìš©)')
    parser.add_argument('--target_column', type=str, default='target',
                       help='íƒ€ê²Ÿ ì»¬ëŸ¼ëª… (ê¸°ë³¸ê°’: target)')
    parser.add_argument('--sample_size', type=int, default=None,
                       help='ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒ˜í”Œë§ í¬ê¸° (ê¸°ë³¸ê°’: ì „ì²´ ë°ì´í„°)')
    
    args = parser.parse_args()
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        if args.mode == 'load':
            # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ëª¨ë“œ
            if not args.model_path:
                print("âŒ load ëª¨ë“œì—ì„œëŠ” --model_pathê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return
            
            if not args.data_path:
                print("âŒ load ëª¨ë“œì—ì„œëŠ” --data_pathê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                print("ğŸ’¡ ëª¨ë¸ê³¼ í˜¸í™˜ë˜ëŠ” ë°ì´í„° íŒŒì¼ì„ ì§€ì •í•´ì£¼ì„¸ìš”.")
                print("   ì˜ˆ: --data_path 'titanic_data.csv'")
                return
            
            print(f"\n=== ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ: {args.model_path} ===")
            try:
                predictor = TabularPredictor.load(args.model_path)
                print(f"âœ… ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {args.model_path}")
                
                # ëª¨ë¸ê³¼ í˜¸í™˜ë˜ëŠ” ë°ì´í„° ë¡œë“œ
                print(f"=== ëª¨ë¸ í˜¸í™˜ ë°ì´í„° ë¡œë“œ: {args.data_path} ===")
                df = pd.read_csv(args.data_path)
                print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {df.shape}")
                
                # ë°ì´í„° ìƒ˜í”Œë§ (sample_sizeê°€ ëª…ì‹œëœ ê²½ìš°ì—ë§Œ)
                if args.sample_size:
                    print(f"ğŸ“Š ëª…ì‹œì  ìƒ˜í”Œë§: {len(df)} â†’ {args.sample_size}")
                    
                    # Positive class ì „ì²´ í¬í•¨ + Negative classë¡œ ë‚˜ë¨¸ì§€ ì±„ìš°ê¸°
                    positive_data = df[df[args.target_column] == 1]
                    negative_data = df[df[args.target_column] == 0]
                    
                    # Positive class ì „ì²´ í¬í•¨
                    positive_sample = positive_data.copy()
                    
                    # Negative classëŠ” ë‚˜ë¨¸ì§€ ê³µê°„ë§Œí¼
                    negative_sample_size = args.sample_size - len(positive_sample)
                    negative_sample = negative_data.sample(n=negative_sample_size, random_state=42)
                    
                    # ìƒ˜í”Œë§ëœ ë°ì´í„° ì¬ì¡°í•©
                    df = pd.concat([positive_sample, negative_sample], axis=0)
                    print(f"âœ… ìƒ˜í”Œë§ ì™„ë£Œ: {df.shape}")
                    print(f"ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬: {df[args.target_column].value_counts().to_dict()}")
                else:
                    print(f"ğŸ“Š ì „ì²´ ë°ì´í„° ì‚¬ìš©: {len(df)}ê°œ (ìƒ˜í”Œë§ ì—†ìŒ)")
                
                # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ (ìƒ˜í”Œë§ëœ ë°ì´í„° ì „ì²´ ì‚¬ìš©)
                if args.test_data_path and os.path.exists(args.test_data_path):
                    # ë³„ë„ í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ì‚¬ìš©
                    test_df = pd.read_csv(args.test_data_path)
                    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {test_df.shape}")
                else:
                    # ìƒ˜í”Œë§ëœ ë°ì´í„° ì „ì²´ë¥¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ìš©
                    test_df = df.copy()
                    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„: {test_df.shape}")
                    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬: {test_df[args.target_column].value_counts().to_dict()}")
                
                # 3. Stacking ëª¨ë¸ ë¶„ì„
                analyze_stacking_models(predictor)
                
                # 4. Stacking ëŒ€ì‹œë³´ë“œ ìƒì„±
                create_stacking_dashboard(predictor, test_df, args.target_column)
                
            except Exception as e:
                print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return
                
        else:
            # ìƒˆ ëª¨ë¸ í•™ìŠµ ëª¨ë“œ
            print("\n=== ìƒˆë¡œìš´ Stacking ëª¨ë¸ í•™ìŠµ ===")
            
            # ë°ì´í„° ë¡œë“œ (train ëª¨ë“œ)
            if args.data_path and os.path.exists(args.data_path):
                # íŒŒì¼ ê²½ë¡œê°€ ì œê³µëœ ê²½ìš°
                print(f"=== íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ: {args.data_path} ===")
                df = pd.read_csv(args.data_path)
                print(f"âœ… íŒŒì¼ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {df.shape}")
            else:
                # ê¸°ë³¸ sklearn ë°ì´í„° ì‚¬ìš©
                print("=== sklearn ë°ì´í„° ë¡œë“œ ===")
                df = load_sklearn_data()
                if df is None:
                    print("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    return
            
            # 2. Stacking ëª¨ë¸ í•™ìŠµ
            predictor, test_df = train_stacking_model(df)
            
            # 3. Stacking ëª¨ë¸ ë¶„ì„
            analyze_stacking_models(predictor)
            
            # 4. Stacking ëŒ€ì‹œë³´ë“œ ìƒì„±
            create_stacking_dashboard(predictor, test_df, args.target_column)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 